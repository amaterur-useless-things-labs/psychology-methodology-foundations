# Lecture 28: Scientific Honesty and Open Science: Problems and Solutions

## 1. Introduction

Scientific honesty is foundation of science. But what does it mean to be honest in science? What practices violate scientific honesty? How to ensure scientific honesty?

In this lecture, we will examine scientific honesty and open science: problems (p-hacking, HARKing, publication bias, salami slicing), solutions (open science, preregistration, registered reports), and what it means to be honest in science.

**Lecture goal:** Understand problems of scientific honesty, their causes, and solutions through open science.

---

## 2. Problem Statement

### The Problem of Scientific Honesty

**Why is this important?**

Scientific honesty is foundation of science. But in science there are practices that violate scientific honesty:
- **P-Hacking:** data manipulations for significant results
- **HARKing:** formulating hypotheses after obtaining results
- **Publication Bias:** only significant results published
- **Salami Slicing:** breaking one study into multiple publications

These practices undermine trust in science and hinder progress.

**Problem:**

**Problem 1: Violations of Scientific Honesty**
- P-hacking, HARKing, publication bias, salami slicing
- Undermine trust in science
- Hinder progress

**Problem 2: Systemic Factors**
- Pressure to publish
- Competition for funding
- Absence of punishment for violations

**Problem 3: Absence of Openness**
- Data, code not available
- Cannot verify results
- Cannot reproduce

**Solution:**

**Open Science:**
- Open data, code, materials
- Preregistration: registering hypotheses before data collection
- Registered Reports: peer review before data collection
- Publishing null results

**These problems are important for understanding science.** Need to understand problems and solutions.

---

## 3. Main Thoughts and Ideas

### 3.1. Problems: P-Hacking, HARKing, Publication Bias, Salami Slicing

**1. P-Hacking (Data Manipulations)**

**What is This?**

P-hacking — data manipulations to obtain significant results (p < 0.05):
- Excluding outliers until significance
- Changing dependent variables
- Stopping data collection after obtaining significance
- Testing multiple hypotheses without correction

**Examples:**

1. **Excluding Outliers:**
   - Test hypothesis
   - If not significant, exclude outliers
   - Repeat until significance

2. **Changing Variables:**
   - Test hypothesis
   - If not significant, transform variables
   - Repeat until significance

3. **Stopping Data Collection:**
   - Collect data gradually
   - Test after each addition
   - Stop after obtaining significance

**Problem:**

P-hacking distorts results:
- Increases number of false positive results
- Undermines trust in science
- Hinders progress

**Literature:**
- **Joseph Simmons, Leo Nelson, Uri Simonsohn, "False-Positive Psychology"** (2011, English)
  - On problem of p-hacking

**2. HARKing (Hypothesizing After Results are Known)**

**What is This?**

HARKing — formulating hypotheses after obtaining results:
- Collect data
- Analyze
- Formulate hypotheses fitting results
- Publish as confirmatory study

**Examples:**

1. **Exploratory Study as Confirmatory:**
   - Collect data to search for patterns
   - Find significant relationship
   - Reformulate as hypothesis
   - Publish as confirmatory study

2. **Multiple Hypotheses:**
   - Test multiple hypotheses
   - Choose significant ones
   - Publish as pre-formulated hypotheses

**Problem:**

HARKing distorts scientific process:
- Blurs distinction between confirmatory and exploratory research
- Increases number of false positive results
- Undermines trust in science

**Literature:**
- **Norbert Kerr, "HARKing: Hypothesizing After the Results are Known"** (1998, English)
  - On problem of HARKing

**3. Publication Bias**

**What is This?**

Publication bias — tendency to publish only significant results:
- Significant results published
- Non-significant results not published
- Distorts literature

**Examples:**

1. **Tendency to Publish Significant Results:**
   - Journals prefer significant results
   - Editors reject non-significant results
   - Researchers do not publish non-significant results

2. **File-Drawer:**
   - Non-significant results remain in file-drawer
   - Do not enter literature
   - Distort picture

**Problem:**

Publication bias distorts literature:
- Distorts estimates of effects
- Hinders meta-analysis
- Undermines trust in science

**Literature:**
- **Robert Rosenthal, "The File-Drawer Problem and Tolerance for Null Results"** (1979, English)
  - On problem of publication bias

**4. Salami Slicing**

**What is This?**

Salami slicing — breaking one study into multiple publications:
- One study published as multiple articles
- Each article on small question
- Increases number of publications

**Examples:**

1. **Breaking by Variables:**
   - One study with multiple variables
   - Each article on one variable
   - Multiple publications

2. **Breaking by Samples:**
   - One study with multiple samples
   - Each article on one sample
   - Multiple publications

**Problem:**

Salami slicing distorts literature:
- Hinders understanding of full picture
- Increases number of publications without increasing knowledge
- Undermines trust in science

**Literature:**
- **John Ioannidis, "Why Most Published Research Findings Are False"** (2005, English)
  - On problems of scientific publication

### 3.2. Solutions: Open Science, Preregistration, Registered Reports

**1. Open Science**

**What is This?**

Open Science — openness of data, code, materials:
- **Open Data:** data available for verification
- **Open Code:** analysis code available
- **Open Materials:** stimuli, protocols available
- **Preprints:** publication before peer review

**Advantages:**

1. **Verification:**
   - Can verify results
   - Can verify analysis
   - Can verify methods

2. **Reproducibility:**
   - Can reproduce study
   - Can verify results
   - Can use data

3. **Transparency:**
   - Transparent scientific process
   - Can see all stages
   - Increases trust

**Problems:**

1. **Confidentiality:**
   - Some data confidential
   - Need to protect participants
   - How to ensure openness with confidentiality?

2. **Time:**
   - Preparing open data requires time
   - Need additional time
   - How to motivate?

**Literature:**
- **Brian Nosek, Jeffrey Spence, "Open Science: Principles and Practices"** (2012, English)
  - On open science

**2. Preregistration**

**What is This?**

Preregistration — registering hypotheses, methods, analysis before data collection:
- Register hypotheses in advance
- Register methods in advance
- Register analysis plan in advance
- Prevents HARKing and p-hacking

**Advantages:**

1. **Preventing HARKing:**
   - Hypotheses registered in advance
   - Cannot formulate after obtaining results
   - Distinguishes confirmatory and exploratory research

2. **Preventing P-Hacking:**
   - Analysis plan registered in advance
   - Cannot change after obtaining results
   - Reduces manipulations

3. **Transparency:**
   - Transparent scientific process
   - Can see all stages
   - Increases trust

**Problems:**

1. **Flexibility:**
   - Research requires flexibility
   - Need to adapt to data
   - How to balance flexibility and preregistration?

2. **Exploratory Research:**
   - Exploratory research cannot be preregistered
   - But important for science
   - How to handle?

**Literature:**
- **Norbert Kerr, "Preregistration: Golden Line Between Confirmation and Exploration"** (2019, English)
  - On preregistration

**3. Registered Reports**

**What is This?**

Registered Reports — peer review before data collection:
- Submit hypotheses, methods, analysis plan
- Peer review before data collection
- After approval collect data and publish regardless of results

**Advantages:**

1. **Preventing Publication Bias:**
   - Accepted before data collection
   - Published regardless of results
   - Reduces publication bias

2. **Quality:**
   - Peer review before data collection
   - Improves quality of research
   - Reduces errors

3. **Focus on Process:**
   - Focus on process, not results
   - Quality valued, not significance
   - Changes culture

**Problems:**

1. **Time:**
   - Requires more time
   - Peer review before and after
   - How to motivate?

2. **Inapplicability:**
   - Not all studies can be preregistered
   - Exploratory research not suitable
   - How to handle?

**Literature:**
- **Chris Chambers, "Registered Reports: New Form of Publication"** (2013, English)
  - On registered reports

### 3.3. What Does It Mean to Be Honest in Science?

**Main Principles:**

**1. Honest Presentation of Data:**
- Not falsify data
- Not fabricate data
- Not distort data

**2. Honest Analysis:**
- Not p-hack
- Not HARK
- Follow registered plan

**3. Honest Publication:**
- Publish all results, including non-significant
- Not salami slicing
- Honestly present limitations

**4. Honest Recognition:**
- Recognize limitations
- Recognize errors
- Correctly cite and recognize contribution of others

**5. Openness:**
- Make data available
- Make code available
- Make materials available

**Problem:**

**When We Are Dishonest:**

1. **Unconsciously:**
   - Do not realize practices as problematic
   - Example: p-hacking without realizing problem

2. **Under Pressure:**
   - Pressure to publish
   - Pressure to get significant results
   - Example: HARKing under pressure

3. **Intentionally:**
   - Intentional falsification
   - Intentional fabrication
   - Example: falsifying data

**Solution:**

**1. Education:**
- Teaching scientific honesty
- Understanding problematic practices
- Understanding solutions

**2. Systemic Changes:**
- Changing evaluation system
- Value process, not only results
- Support open science

**3. Culture:**
- Culture of scientific honesty
- Culture of openness
- Culture of recognizing errors

**Literature:**
- **David Rescorla, "Scientific Honesty"** (2014, English)
  - On scientific honesty

---

## 4. Conclusions

**Key Ideas of the Lecture:**

1. **Problems of Scientific Honesty:**
   - **P-Hacking:** data manipulations for significant results
   - **HARKing:** formulating hypotheses after obtaining results
   - **Publication Bias:** only significant results published
   - **Salami Slicing:** breaking one study into multiple publications

2. **Solutions:**
   - **Open Science:** openness of data, code, materials
   - **Preregistration:** registering hypotheses, methods, analysis before data collection
   - **Registered Reports:** peer review before data collection

3. **What It Means to Be Honest in Science:**
   - Honest presentation of data
   - Honest analysis
   - Honest publication
   - Honest recognition
   - Openness

4. **Systemic Factors:**
   - Pressure to publish
   - Competition for funding
   - Absence of punishment for violations

5. **Cultural Changes:**
   - Education
   - Systemic changes
   - Culture of scientific honesty

**Practical Conclusions:**

1. **Understanding Problems:** Understanding problems of scientific honesty important for critical evaluation of research

2. **Using Solutions:** Using solutions (open science, preregistration) important for scientific honesty

3. **Culture of Honesty:** Important to create culture of scientific honesty

4. **Ethical Reflection:** Ethical reflection on scientific honesty important

---

## 5. Problems

**Open Questions:**

1. **How to Ensure Scientific Honesty?**
   - What mechanisms needed?
   - How to motivate honesty?
   - How to punish dishonesty?

2. **Balance of Flexibility and Honesty:**
   - How to balance flexibility and preregistration?
   - Is flexibility needed in research?
   - How to ensure?

3. **Exploratory Research:**
   - How to handle exploratory research?
   - Need preregistration?
   - How to distinguish from confirmatory?

4. **Confidentiality:**
   - How to ensure openness with confidentiality?
   - What data can be opened?
   - How to protect participants?

5. **Systemic Changes:**
   - How to change evaluation system?
   - How to change culture?
   - What needs to change?

**Practical Problems:**

1. **Applying Open Science:**
   - How to apply in practice?
   - What barriers are there?
   - How to overcome them?

2. **Preregistration:**
   - How to preregister studies?
   - What platforms to use?
   - How to train?

3. **Culture:**
   - How to create culture of scientific honesty?
   - How to motivate?
   - How to support?

**These problems do not have simple answers.** Need to understand problems and search for solutions. Important are systemic changes and cultural changes.

---

## 6. Where to Look for Further Study

### Main Literature

**On Problems of Scientific Honesty:**

1. **Joseph Simmons, Leo Nelson, Uri Simonsohn, "False-Positive Psychology"** (2011, English)
   - On problem of p-hacking

2. **Norbert Kerr, "HARKing: Hypothesizing After the Results are Known"** (1998, English)
   - On problem of HARKing

3. **Robert Rosenthal, "The File-Drawer Problem and Tolerance for Null Results"** (1979, English)
   - On problem of publication bias

4. **John Ioannidis, "Why Most Published Research Findings Are False"** (2005, English)
   - On problems of scientific publication

**On Solutions:**

5. **Brian Nosek, Jeffrey Spence, "Open Science: Principles and Practices"** (2012, English)
   - On open science

6. **Norbert Kerr, "Preregistration: Golden Line Between Confirmation and Exploration"** (2019, English)
   - On preregistration

7. **Chris Chambers, "Registered Reports: New Form of Publication"** (2013, English)
   - On registered reports

**On Scientific Honesty:**

8. **David Rescorla, "Scientific Honesty"** (2014, English)
   - On scientific honesty

### Online Resources

**Open Science Framework:**
- osf.io — platform for open science

**Preregistration Platforms:**
- aspredicted.org — platform for preregistration
- cos.io/prereg — preregistration center

**Registered Reports Registration:**
- cos.io/rr — information on registered reports

**Stanford Encyclopedia of Philosophy:**
- "Scientific Objectivity" (plato.stanford.edu/entries/scientific-objectivity/)
- "Research Ethics" (plato.stanford.edu/entries/research-ethics/)

### Practical Assignments

1. Preregister study:
   - Formulate hypotheses
   - Describe methods
   - Describe analysis plan
   - Register on platform

2. Make study open:
   - Open data (if possible)
   - Open code
   - Open materials

3. Analyze article for scientific honesty:
   - Are there signs of p-hacking?
   - Are there signs of HARKing?
   - Are data, code available?
   - Are results honestly presented?

**Recommendation:** Start by reading Simmons et al. work "False-Positive Psychology" — it shows problem of p-hacking. Then study solutions (Nosek and Spence on open science, Chambers on registered reports). Try preregistering your study or making it open — this will help understand in practice.

